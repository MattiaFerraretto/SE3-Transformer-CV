{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47761820ef1c4de093b06e9b9f111030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caffdddd23df4af68002f20dbb011a79",
              "IPY_MODEL_fbc653fcc1004f469a230db9a442bdb6"
            ],
            "layout": "IPY_MODEL_f7864bef67324feb91f257bde9fb1c83"
          }
        },
        "caffdddd23df4af68002f20dbb011a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_860edc2939454c7c8128882bb5877fa9",
            "placeholder": "​",
            "style": "IPY_MODEL_e37fae98e055439cabc329b27c185b29",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "fbc653fcc1004f469a230db9a442bdb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c6ea575d6044e0bd7ae549ee467c98",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a31508ddbd2d402eac25b0fdf27ebbd6",
            "value": 1
          }
        },
        "f7864bef67324feb91f257bde9fb1c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "860edc2939454c7c8128882bb5877fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37fae98e055439cabc329b27c185b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c6ea575d6044e0bd7ae549ee467c98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a31508ddbd2d402eac25b0fdf27ebbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDZgHa8vyEsD"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "#!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "#!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "#!pip install open3d\n",
        "!pip install plotly\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "6yN-5rwcyYFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7c3363-3f1a-4683-ed49-da0c91982c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import EdgeConv, global_max_pool\n",
        "from torch_geometric.nn import knn_graph\n",
        "\n",
        "class EdgeConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EdgeConvBlock, self).__init__()\n",
        "        self.edgeconv = EdgeConv(nn.Sequential(\n",
        "            nn.Linear(in_channels * 2, 64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(64),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(64),\n",
        "            nn.Linear(64, out_channels)\n",
        "        ))\n",
        "        #self.lnrm = nn.LayerNorm(out_channels)\n",
        "        #self.leaky_relu = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.edgeconv(x, edge_index)\n",
        "        #x = self.edgeconv(x, edge_index)\n",
        "        #x = self.leaky_relu(self.lnrm(x))\n",
        "        #return x\n",
        "\n",
        "class DGCNN_seg(nn.Module):\n",
        "    def __init__(self, n_points, in_channels, n_classes, k=40):\n",
        "        super(DGCNN_seg, self).__init__()\n",
        "        self.n_classes = n_classes\n",
        "        self.n_points = n_points\n",
        "        self.k = k\n",
        "\n",
        "        self.edge_conv1 = EdgeConvBlock(in_channels, 64)\n",
        "        self.edge_conv2 = EdgeConvBlock(64, 64)\n",
        "        self.edge_conv3 = EdgeConvBlock(64, 64)\n",
        "\n",
        "        self.fc_agg = nn.Linear(192, 1024)\n",
        "        '''self.fc_agg = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(1024)\n",
        "        )'''\n",
        "\n",
        "        #self.fc_seg_ft = nn.Linear(n_points, 64)\n",
        "        self.fc_lb_emb = nn.Sequential(\n",
        "            nn.Linear(n_points, 64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(64)\n",
        "        )\n",
        "        #self.fc_lb_emb = nn.Linear(n_classes, 64)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1280, 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels: torch.tensor=None, batch: torch.tensor=None, batch_size: int=None):\n",
        "        edge_index = knn_graph(x, k=self.k, batch=batch)\n",
        "        x1 = self.edge_conv1(x, edge_index)\n",
        "\n",
        "        edge_index = knn_graph(x1, k=self.k, batch=batch)\n",
        "        x2 = self.edge_conv2(x1, edge_index)\n",
        "\n",
        "        edge_index = knn_graph(x2, k=self.k, batch=batch)\n",
        "        x3 = self.edge_conv3(x2, edge_index)\n",
        "\n",
        "        x = torch.cat([x1, x2, x3], dim=1)\n",
        "\n",
        "        # Aggregate multi-scale features\n",
        "        #x = F.leaky_relu(self.fc_agg(x))\n",
        "        x = self.fc_agg(x)\n",
        "\n",
        "        '''Possibile option, one hot encoding of labels\n",
        "        if labels is not None:\n",
        "          lb_emb = self.fc_lb_emb(labels)\n",
        "        else:\n",
        "          lb_emb = torch.zeros(x.shape[0], 64, device=x.device)\n",
        "\n",
        "        x = torch.cat([x, lb_emb], dim=1)'''\n",
        "\n",
        "        x = global_max_pool(x, batch)\n",
        "\n",
        "\n",
        "        if labels is not None:\n",
        "            #seg_ft = self.fc_seg_ft(labels.view(x.shape[0], -1).float())\n",
        "            lb_emb = self.fc_lb_emb(\n",
        "                labels.view(x.shape[0], -1).float()\n",
        "            )\n",
        "        else:\n",
        "            lb_emb = torch.zeros(x.shape[0], 64, device=x.device)\n",
        "\n",
        "        x = torch.cat([x, lb_emb], dim=1)\n",
        "        x = torch.repeat_interleave(x, self.n_points, dim=0)\n",
        "\n",
        "        x = torch.cat([x1, x2, x3, x], dim=1)\n",
        "\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        #return x.view(-1, self.n_points, self.n_classes)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NByCBhZbycJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import MessagePassing, knn_graph, global_max_pool\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "\n",
        "class EGCNNBlock(MessagePassing):\n",
        "    \"\"\"EGNN layer from https://arxiv.org/pdf/2102.09844.pdf\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        hidden_channels: int = 64,\n",
        "        out_channels: int = 64,\n",
        "        aggr: str = 'add'\n",
        "    ):\n",
        "        super(EGCNNBlock, self).__init__(aggr=aggr)\n",
        "\n",
        "        self.phi_e = nn.Sequential(\n",
        "                nn.Linear(2 * in_channels + 1, hidden_channels),\n",
        "                nn.LayerNorm(hidden_channels),\n",
        "                nn.SiLU(),\n",
        "                nn.Linear(hidden_channels, hidden_channels),\n",
        "                nn.LayerNorm(hidden_channels),\n",
        "                nn.SiLU()\n",
        "        )\n",
        "\n",
        "        self.phi_x = nn.Sequential(\n",
        "                nn.Linear(hidden_channels, hidden_channels),\n",
        "                nn.LayerNorm(hidden_channels),\n",
        "                nn.SiLU(),\n",
        "                nn.Linear(hidden_channels, 1)\n",
        "        )\n",
        "\n",
        "        self.phi_h = nn.Sequential(\n",
        "            nn.Linear(in_channels + hidden_channels, hidden_channels),\n",
        "            nn.LayerNorm(hidden_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(64, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, h, edge_index, c):\n",
        "        #if c is None:\n",
        "        #    c = degree(edge_index[0], x.shape[0]).unsqueeze(-1)\n",
        "        return self.propagate(edge_index=edge_index, x=x, h=h, c=c)\n",
        "\n",
        "    def message(self, x_i, x_j, h_i, h_j):\n",
        "        mh_ij = self.phi_e(torch.cat([h_i, h_j, torch.norm(x_i - x_j, dim=-1, keepdim=True)**2], dim=-1))\n",
        "        mx_ij = (x_i - x_j) * self.phi_x(mh_ij)\n",
        "        return torch.cat([mx_ij, mh_ij], dim=-1)\n",
        "\n",
        "    def update(self, aggr_out, x, h, c):\n",
        "        m_x, m_h = aggr_out[:, :3], aggr_out[:, 3:]\n",
        "        h_l1 = self.phi_h(torch.cat([h, m_h], dim=-1)) #+ h\n",
        "        x_l1 = x + (m_x / c)\n",
        "        return x_l1, h_l1\n",
        "\n",
        "class EDGCNN_seg(nn.Module):\n",
        "    def __init__(self, n_points, in_channels, n_classes, k=40):\n",
        "        super(EDGCNN_seg, self).__init__()\n",
        "        self.n_classes = n_classes\n",
        "        self.n_points = n_points\n",
        "        self.k = k\n",
        "\n",
        "        self.egcnn1 = EGCNNBlock(in_channels, 64)\n",
        "        self.egcnn2 = EGCNNBlock(64, 64)\n",
        "        self.egcnn3 = EGCNNBlock(64, 64)\n",
        "\n",
        "        self.fc_agg = nn.Linear(192 + 9, 1024)\n",
        "        '''self.fc_agg = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(1024)\n",
        "        )'''\n",
        "\n",
        "        #self.fc_seg_ft = nn.Linear(n_points, 64)\n",
        "        self.fc_lb_emb = nn.Sequential(\n",
        "            nn.Linear(n_points, 64),\n",
        "            nn.LayerNorm(64),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        #self.fc_lb_emb = nn.Linear(n_classes, 64)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1280 + 9, 256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels: torch.tensor=None, batch: torch.tensor=None, batch_size: int=None):\n",
        "        c = 1/(batch_size - 1)\n",
        "\n",
        "        edge_index = knn_graph(x, k=self.k, batch=batch)\n",
        "        m1, h1 = self.egcnn1(x, x, edge_index, c)\n",
        "\n",
        "        edge_index = knn_graph(m1, k=self.k, batch=batch)\n",
        "        m2, h2 = self.egcnn2(m1, h1, edge_index, c)\n",
        "\n",
        "        edge_index = knn_graph(m2, k=self.k, batch=batch)\n",
        "        m3, h3 = self.egcnn3(m2, h2, edge_index, c)\n",
        "\n",
        "        x = torch.cat([m1, h1, m2, h2, m3, h3], dim=1)\n",
        "\n",
        "        # Aggregate multi-scale features\n",
        "        #x = F.leaky_relu(self.fc_agg(x))\n",
        "        x = self.fc_agg(x)\n",
        "\n",
        "        '''Possibile option, one hot encoding of labels\n",
        "        if labels is not None:\n",
        "          lb_emb = self.fc_lb_emb(labels)\n",
        "        else:\n",
        "          lb_emb = torch.zeros(x.shape[0], 64, device=x.device)\n",
        "\n",
        "        x = torch.cat([x, lb_emb], dim=1)'''\n",
        "\n",
        "        x = global_max_pool(x, batch)\n",
        "\n",
        "\n",
        "        if labels is not None:\n",
        "            #seg_ft = self.fc_seg_ft(labels.view(x.shape[0], -1).float())\n",
        "            lb_emb = self.fc_lb_emb(\n",
        "                labels.view(x.shape[0], -1).float()\n",
        "            )\n",
        "        else:\n",
        "            lb_emb = torch.zeros(x.shape[0], 64, device=x.device)\n",
        "\n",
        "        x = torch.cat([x, lb_emb], dim=1)\n",
        "        x = torch.repeat_interleave(x, self.n_points, dim=0)\n",
        "\n",
        "        x = torch.cat([m1, h1, m2, h2, m3, h3, x], dim=1)\n",
        "        #return x\n",
        "\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        #return x.view(-1, self.n_points, self.n_classes)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "x2AdWqD1gbXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def pointcloud(ptc: Data):\n",
        "  # Access point coordinates and labels\n",
        "  points = ptc.pos.numpy()\n",
        "  labels = ptc.y.numpy()\n",
        "\n",
        "  # Create a color map\n",
        "  unique_labels = np.unique(labels)\n",
        "  color_scale = px.colors.qualitative.Plotly  # You can choose other color scales like 'Set1', 'Pastel', etc.\n",
        "  color_map = {label: color_scale[i % len(color_scale)] for i, label in enumerate(unique_labels)}\n",
        "\n",
        "  point_colors = [color_map[label] for label in labels]\n",
        "\n",
        "  # Create the 3D scatter plot\n",
        "  fig = go.Figure(data=[go.Scatter3d(\n",
        "      x=points[:, 0],\n",
        "      y=points[:, 1],\n",
        "      z=points[:, 2],\n",
        "      mode='markers',\n",
        "      marker=dict(\n",
        "        size=2,\n",
        "        color=point_colors,\n",
        "        opacity=0.8\n",
        "      ),\n",
        "      text=[f'Label: {label}' for label in labels],\n",
        "      hoverinfo='text'\n",
        "  )])\n",
        "\n",
        "  # Update the layout\n",
        "  fig.update_layout(\n",
        "      title=f\"Pointcloud's category: {ptc.category.item()}\",\n",
        "      scene=dict(\n",
        "          xaxis_title='X',\n",
        "          yaxis_title='Y',\n",
        "          zaxis_title='Z'\n",
        "      ),\n",
        "      width=800,\n",
        "      height=800,\n",
        "  )\n",
        "\n",
        "  # Show the plot\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "seaxb8GRdmZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import fps\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FPSSampler:\n",
        "    def __init__(self, num_points,  num_classes):\n",
        "        self.num_points = num_points\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def __call__(self, data):\n",
        "        index = fps(data.pos, ratio=self.num_points / data.pos.size(0))\n",
        "        y_onehot = F.one_hot(data.y[index], self.num_classes).float()\n",
        "        return Data(x=data.x[index], y=data.y[index], y_onehot=y_onehot, pos=data.pos[index], category=data.category)"
      ],
      "metadata": {
        "id": "lgHAZ6aStH9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import ShapeNet\n",
        "from torch_geometric.transforms import Compose\n",
        "\n",
        "sp_train = ShapeNet('data', split='train')\n",
        "sp_test = ShapeNet('data', split='test')\n",
        "\n",
        "#shapeNet.transform = Compose([FPSSampler(2048, 50)])\n",
        "\n",
        "sp_train.transform = Compose([FPSSampler(2048, 50)])\n",
        "sp_test.transdofrm = Compose([FPSSampler(2048, 50)])"
      ],
      "metadata": {
        "id": "ds-8Ikq8DFmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import InMemoryDataset\n",
        "\n",
        "def train_eval_split(dataset: InMemoryDataset, eval_size: float):\n",
        "  index = torch.rand(len(dataset)) < (1 - eval_size)\n",
        "  return dataset[index], dataset[~index]"
      ],
      "metadata": {
        "id": "uMxo7gOSC4_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import wandb\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate(model: nn.Module, eval_set: DataLoader, criterion: nn.CrossEntropyLoss, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for datapt in eval_set:\n",
        "            inputs, labels = datapt.pos.to(device), datapt.y.to(device)\n",
        "            outputs = model(\n",
        "                inputs,\n",
        "                batch=datapt.batch.to(device),\n",
        "                batch_size=datapt.batch_size\n",
        "            )\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(eval_set)\n",
        "\n",
        "def save_checkpoint(model: nn.Module, optimizer: Adam, epoch: int, val_loss: float, config):\n",
        "    if (epoch + 1) % config['hyper']['save_every'] != 0:\n",
        "      return\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'val_loss': val_loss,\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(config['hyper']['checkpoint_dir']):\n",
        "        os.makedirs(config['hyper']['checkpoint_dir'])\n",
        "\n",
        "    path = os.path.join(config['hyper']['checkpoint_dir'], f'checkpoint-{epoch+1}.pth')\n",
        "    torch.save(checkpoint, path)\n",
        "\n",
        "    checkpoints = [f for f in os.listdir(config['hyper']['checkpoint_dir']) if f.startswith('checkpoint-')]\n",
        "    checkpoints.sort(key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
        "    while len(checkpoints) > config['hyper']['max_checkpoints']:\n",
        "        os.remove(os.path.join(config['hyper']['checkpoint_dir'], checkpoints.pop(0)))\n",
        "\n",
        "\n",
        "\n",
        "def train(model: nn.Module, train_set: DataLoader, eval_set: DataLoader, config):\n",
        "    wandb.init(\n",
        "        project=config['init']['project'],\n",
        "        name=config['init']['run_name'],\n",
        "        config=config['hyper']\n",
        "    )\n",
        "\n",
        "    model.to(config['hyper']['device'])\n",
        "    optimizer = SGD(model.parameters(), lr=config['hyper']['learning_rate'], momentum=0.9)\n",
        "    #optimizer = Adam(model.parameters(), lr=config['hyper']['learning_rate'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    scheduler = CosineAnnealingLR(optimizer, config['hyper']['epochs'], eta_min=0.001)\n",
        "\n",
        "    for epoch in range(config['hyper']['epochs']):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, datapt in enumerate(tqdm(train_set, desc=f\"Epoch {epoch+1}/{config['hyper']['epochs']}\")):\n",
        "            use_labels = torch.rand(1).item() < config['hyper']['use_labels_prob']\n",
        "\n",
        "            y_hat = model(\n",
        "                datapt.pos.to(config['hyper']['device']),\n",
        "                #datapt.y_onehot.to(config['hyper']['device']) if use_labels else None,\n",
        "                datapt.y.to(config['hyper']['device']) if use_labels else None,\n",
        "                datapt.batch.to(config['hyper']['device']),\n",
        "                datapt.batch_size\n",
        "            )\n",
        "\n",
        "            loss = criterion(\n",
        "                y_hat,\n",
        "                datapt.y.to(config['hyper']['device'])\n",
        "            )\n",
        "\n",
        "            loss = loss / config['hyper']['gradient_accumulation_steps']\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            if (i + 1) % config['hyper']['gradient_accumulation_steps'] == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            running_loss += loss.item() * config['hyper']['gradient_accumulation_steps']\n",
        "\n",
        "            if i % config['hyper']['logging_steps'] == 0:\n",
        "                wandb.log({\n",
        "                    \"train_loss\": loss.item() * config['hyper']['gradient_accumulation_steps']\n",
        "                })\n",
        "\n",
        "        if (i + 1) % config['hyper']['gradient_accumulation_steps'] != 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_set)\n",
        "\n",
        "        val_loss = evaluate(\n",
        "            model,\n",
        "            eval_set,\n",
        "            criterion,\n",
        "            config['hyper']['device']\n",
        "        )\n",
        "\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "        })\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['hyper']['epochs']}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        save_checkpoint(\n",
        "            model,\n",
        "            optimizer,\n",
        "            epoch,\n",
        "            val_loss,\n",
        "            config\n",
        "        )\n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "zRiec7SV_cCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = {\n",
        "    'init': {\n",
        "        'project': 'DGCNN',\n",
        "        'run_name': 'edgcnn-seg-v0.0.4'\n",
        "    },\n",
        "    'hyper':{\n",
        "        'epochs': 3,\n",
        "        'learning_rate': 0.01,\n",
        "        'batch_training_size': 18,\n",
        "        'batch_eval_size': 18,\n",
        "        'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "        'gradient_accumulation_steps': 1,\n",
        "        'logging_steps': 5,\n",
        "        'checkpoint_dir': 'checkpoints',\n",
        "        'save_every': 1,\n",
        "        'save_max': 3,\n",
        "        'dataset': 'ShapeNet',\n",
        "        'optimizer': 'SGD',\n",
        "        'optimizer_kwargs': {'momentum': 0.9},\n",
        "        'scheduler': 'CosineAnelingLr',\n",
        "        'use_labels_prob': 0.7\n",
        "    }\n",
        "}\n",
        "\n",
        "train_set, eval_set = train_eval_split(sp_train, 0.1)"
      ],
      "metadata": {
        "id": "Nme9AME2mKbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EDGCNN_seg(n_points=2048, in_channels=3, n_classes=50)"
      ],
      "metadata": {
        "id": "-_yX6sf2nq51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    model=model,\n",
        "    train_set=DataLoader(train_set, batch_size=conf['hyper']['batch_training_size'], shuffle=True),\n",
        "    eval_set=DataLoader(eval_set, batch_size=conf['hyper']['batch_eval_size'], shuffle=True),\n",
        "    config=conf\n",
        ")\n"
      ],
      "metadata": {
        "id": "HZ2Cug71Cpil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "47761820ef1c4de093b06e9b9f111030",
            "caffdddd23df4af68002f20dbb011a79",
            "fbc653fcc1004f469a230db9a442bdb6",
            "f7864bef67324feb91f257bde9fb1c83",
            "860edc2939454c7c8128882bb5877fa9",
            "e37fae98e055439cabc329b27c185b29",
            "f7c6ea575d6044e0bd7ae549ee467c98",
            "a31508ddbd2d402eac25b0fdf27ebbd6"
          ]
        },
        "id": "FSj2hWsAHenZ",
        "outputId": "c2428f4f-4050-4955-bb82-0f21d04431b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47761820ef1c4de093b06e9b9f111030"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▇▅▄▄▂█▄▆▁▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>2.61737</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">edgcnn-seg-v0.0.3</strong> at: <a href='https://wandb.ai/mferraretto/DGCNN/runs/xl7n2gd6' target=\"_blank\">https://wandb.ai/mferraretto/DGCNN/runs/xl7n2gd6</a><br/> View project at: <a href='https://wandb.ai/mferraretto/DGCNN' target=\"_blank\">https://wandb.ai/mferraretto/DGCNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240726_160123-xl7n2gd6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}